<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<title>Visualizer</title>
		<style>
			body,
			html {
				margin: 0;
				overflow: hidden;
				background-color: black;
				width: 100%;
				height: 100%;
			}
			#glcanvas {
				position: absolute;
				top: 0;
				left: 0;
				width: 100%;
				height: 100%;
				display: block;
			}
		</style>
	</head>
	<body>
		<canvas id="glcanvas"></canvas>
		<script>
			;(function () {
				// Get the canvas element and set up WebGL2 context
				const canvas = document.getElementById("glcanvas")
				const gl = canvas.getContext("webgl2")

				// If WebGL2 is not supported, alert the user
				if (!gl) {
					alert("WebGL 2 is not supported by your browser.")
					return
				}

				let buffers = [] // To hold the framebuffers used for rendering effects
				let bufferIndex = 0 // Track which framebuffer is currently being rendered

				// Function to create a framebuffer with attached texture
				function createFramebuffer() {
					const framebuffer = gl.createFramebuffer()
					gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer)

					const texture = gl.createTexture()
					gl.bindTexture(gl.TEXTURE_2D, texture)

					// Allocate space for texture
					gl.texImage2D(
						gl.TEXTURE_2D,
						0,
						gl.RGBA8,
						canvas.width,
						canvas.height,
						0,
						gl.RGBA,
						gl.UNSIGNED_BYTE,
						null
					)

					// Set texture parameters
					gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST)
					gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST)
					gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE)
					gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE)

					// Attach the texture to the framebuffer
					gl.framebufferTexture2D(
						gl.FRAMEBUFFER,
						gl.COLOR_ATTACHMENT0,
						gl.TEXTURE_2D,
						texture,
						0
					)

					return { framebuffer, texture }
				}

				// Create two framebuffers used for ping-pong rendering
				function createFramebuffers() {
					if (buffers.length > 0) {
						// Delete existing buffers to avoid memory leaks
						buffers.forEach((buf) => {
							gl.deleteFramebuffer(buf.framebuffer)
							gl.deleteTexture(buf.texture)
						})
					}
					buffers = [createFramebuffer(), createFramebuffer()]
					bufferIndex = 0
				}

				// Resize canvas and update WebGL viewport
				function resizeCanvas() {
					canvas.width = window.innerWidth
					canvas.height = window.innerHeight
					gl.viewport(0, 0, canvas.width, canvas.height)
					createFramebuffers() // Recreate framebuffers to match new size
				}
				window.addEventListener("resize", resizeCanvas)

				resizeCanvas() // Initial canvas setup

				// Vertex shader program: Defines position of vertices and calculates texture coordinates
				const vertexShaderSource = `#version 300 es
      in vec4 a_position;
      out vec2 v_texCoord;
      
      uniform float iAudioLevel;
      uniform float iTime;

      void main() {
          gl_Position = a_position;

          // Calculate the dynamic values based on audio level
          float minVal = 0.5;
          float maxVal = 0.5;
          
          // Threshold volume above which the values start changing
          if (iAudioLevel > 0.1) {
              float volumeFactor = smoothstep(0.001, 0.01, iAudioLevel);
              float cycleOffset = sin(iTime * 1.0 * 3.14159 / (60.0 / 128.0 / 2.0)); // Cycle every 8th beat at 128 BPM
              minVal = 0.49 - 0.000001 * volumeFactor * cycleOffset;
              maxVal = 0.501 - 0.001 * volumeFactor * cycleOffset;
          }

          v_texCoord = a_position.xy * minVal + maxVal;
      }`

				// Fragment shader program: Defines color for each fragment based on noise and audio level
				const fragmentShaderSource = `#version 300 es
      uniform highp float seed;
      precision highp float;
      uniform vec2 iResolution;
      uniform float iTime;
      uniform float iAudioLevel;

      uniform sampler2D iChannel0;
      out vec4 fragColor;
      in vec2 v_texCoord;

      float noise3( vec3 x ) {
          vec3 p = floor(x), f = fract(x);
          f = f*f*(3.0-2.0*f);
          #define hash3(p) fract(sin(1e3*dot(p,vec3(1,57,-13.7)) + seed) * 4375.5453)
          return mix( mix(mix( hash3(p+vec3(0,0,0)), hash3(p+vec3(1,0,0)), f.x),
                          mix( hash3(p+vec3(0,1,0)), hash3(p+vec3(1,1,0)), f.x), f.y),
                      mix(mix( hash3(p+vec3(0,0,1)), hash3(p+vec3(1,0,1)), f.x),
                          mix( hash3(p+vec3(0,1,1)), hash3(p+vec3(1,1,1)), f.x), f.y), f.z);
      }

      #define noise(x) (noise3(x) + noise3(x + 11.5)) / 2.0

      void main() {
          vec2 U = gl_FragCoord.xy;
          vec2 R = iResolution.xy;
          float t = iTime * (1.0 + iAudioLevel * 0.8 * (1.0 - smoothstep(0.5, 1.0, iAudioLevel)));

          // Enhance the effect of the audio level on the noise
          float n = noise(vec3(U * 3.0 / R.y, 0.1 * t + iAudioLevel * 2.0));

          float v = sin(6.28 * 8.0 * n * (1.0 + iAudioLevel * 0.5));

          v = smoothstep(1.0, 0.0, 0.5 * abs(v) / fwidth(v));

          vec4 prevColor = texture(iChannel0, v_texCoord);

          vec4 baseColor = vec4(0.5 - 0.5 * sin(10.0 * n + vec4(35.0 * iAudioLevel + sin(iTime * 0.05), 45.0 * iAudioLevel + cos(iTime * 0.05), 50.0 * iAudioLevel + sin(iTime * 0.05), 0))); // Removed time-based color influence
          vec4 color = mix(vec4(1.0, 1.0, 1.0, 1.0), baseColor, smoothstep(0.01, 0.1, iAudioLevel * 2.0));

          float decayFactor = 0.8 - iAudioLevel * 0.3; // Increase glow intensity with audio level

          fragColor = mix(prevColor * decayFactor, color, v);
      }`

				// Helper function to compile shader source code
				function compileShader(gl, source, type) {
					const shader = gl.createShader(type)
					gl.shaderSource(shader, source)
					gl.compileShader(shader)

					const success = gl.getShaderParameter(shader, gl.COMPILE_STATUS)
					if (!success) {
						console.error(
							"Shader compilation failed:",
							gl.getShaderInfoLog(shader)
						)
						gl.deleteShader(shader)
						return null
					}
					return shader
				}

				// Compile vertex and fragment shaders
				const vertexShader = compileShader(
					gl,
					vertexShaderSource,
					gl.VERTEX_SHADER
				)
				const fragmentShader = compileShader(
					gl,
					fragmentShaderSource,
					gl.FRAGMENT_SHADER
				)

				// Create and link shader program
				const program = gl.createProgram()
				gl.attachShader(program, vertexShader)
				gl.attachShader(program, fragmentShader)
				gl.linkProgram(program)

				// Check if program linked successfully
				if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
					console.error(
						"Program failed to link:",
						gl.getProgramInfoLog(program)
					)
					return
				}
				gl.useProgram(program)

				// Set up position attribute for drawing a rectangle (fullscreen)
				const positionAttributeLocation = gl.getAttribLocation(
					program,
					"a_position"
				)
				const positionBuffer = gl.createBuffer()
				gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer)

				// Fullscreen rectangle vertices
				const positions = new Float32Array([
					-1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1,
				])
				gl.bufferData(gl.ARRAY_BUFFER, positions, gl.STATIC_DRAW)

				gl.enableVertexAttribArray(positionAttributeLocation)
				gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer)
				gl.vertexAttribPointer(
					positionAttributeLocation,
					2,
					gl.FLOAT,
					false,
					0,
					0
				)

				// Uniform locations for resolution, time, and audio level
				const iResolutionLocation = gl.getUniformLocation(
					program,
					"iResolution"
				)
				const iTimeLocation = gl.getUniformLocation(program, "iTime")
				const iAudioLevelLocation = gl.getUniformLocation(
					program,
					"iAudioLevel"
				)
				const iChannel0Location = gl.getUniformLocation(program, "iChannel0")

				function setResolution() {
					// Set the resolution uniform
					gl.uniform2f(iResolutionLocation, canvas.width, canvas.height)
				}
				setResolution()

				let audioDataArray // Array to store frequency data from audio
				let analyserNode // Web Audio API analyser node

				let audioLevel = 0.0 // Current audio level
				let smoothedAudioLevel = 0.0 // Smoothed version of audio level

				// Function to set up microphone input for audio analysis
				async function setupAudio() {
					try {
						const stream = await navigator.mediaDevices.getUserMedia({
							audio: true,
						})
						const audioContext = new (window.AudioContext ||
							window.webkitAudioContext)()
						const source = audioContext.createMediaStreamSource(stream)
						analyserNode = audioContext.createAnalyser()
						analyserNode.fftSize = 1024

						const bufferLength = analyserNode.frequencyBinCount
						audioDataArray = new Uint8Array(bufferLength)

						source.connect(analyserNode)
					} catch (err) {
						console.error("Error accessing microphone:", err)
					}
				}

				setupAudio()

				// Update the current audio level from the analyser node
				function updateAudioLevel() {
					if (analyserNode && audioDataArray) {
						analyserNode.getByteFrequencyData(audioDataArray)

						// Compute average volume
						let sum = 0

						for (let i = 0; i < audioDataArray.length; i++) {
							// Weighted average for different frequency bands
							let frequencyWeight =
								i < audioDataArray.length * 0.2
									? 1.0
									: i < audioDataArray.length * 0.8
									? 0.5
									: 0.1
							sum += audioDataArray[i] * frequencyWeight
						}
						audioLevel = sum / audioDataArray.length / 255.0 // Normalize between 0 and 1

						// Apply smoothing to avoid sudden changes in audio level
						const smoothingFactor = 0.1
						smoothedAudioLevel =
							smoothedAudioLevel * smoothingFactor +
							audioLevel * (1 - smoothingFactor)
					}
				}

				let startTime = null
				let currentSeed = Math.random() * 1000 // Random initial seed for noise
				let seed = currentSeed
				let seedTransitionFactor = 0.0
				let bpm = 128 // Beats per minute
				let interval = (60 / bpm) * 1000 * 8 // Change seed every eight beats
				setInterval(() => {
					if (smoothedAudioLevel > 0.1) {
						// Change shape dynamics only if volume is above a threshold
						currentSeed += (Math.random() - 0.5) * 100 // Gradual adjustment to the current seed for smooth transition
						seedTransitionFactor = 0.0
					}
				}, interval)

				// Render function for drawing the visuals on each animation frame
				function render(time) {
					// Smoothly interpolate the seed value
					seedTransitionFactor = Math.min(
						seedTransitionFactor + 0.02 * smoothedAudioLevel,
						1.0
					)
					seed = currentSeed

					// Set shader uniform values for seed, time, and audio level
					gl.uniform1f(gl.getUniformLocation(program, "seed"), seed)
					if (!startTime) startTime = time
					const deltaTime = (time - startTime) / 1000.0

					updateAudioLevel()

					gl.uniform1f(iTimeLocation, deltaTime)
					gl.uniform1f(iAudioLevelLocation, smoothedAudioLevel)

					setResolution()

					// Use framebuffers for ping-pong rendering
					const currentBuffer = buffers[bufferIndex]
					const prevBuffer = buffers[1 - bufferIndex]

					gl.bindFramebuffer(gl.FRAMEBUFFER, currentBuffer.framebuffer)
					gl.viewport(0, 0, canvas.width, canvas.height)

					gl.activeTexture(gl.TEXTURE0)
					gl.bindTexture(gl.TEXTURE_2D, prevBuffer.texture)
					gl.uniform1i(iChannel0Location, 0)

					gl.clear(gl.COLOR_BUFFER_BIT)

					// Draw to the current framebuffer
					gl.drawArrays(gl.TRIANGLES, 0, 6)

					// Draw to the main canvas
					gl.bindFramebuffer(gl.FRAMEBUFFER, null)
					gl.viewport(0, 0, canvas.width, canvas.height)

					gl.bindTexture(gl.TEXTURE_2D, currentBuffer.texture)

					gl.drawArrays(gl.TRIANGLES, 0, 6)

					// Swap the buffers for the next frame
					bufferIndex = 1 - bufferIndex

					requestAnimationFrame(render)
				}

				requestAnimationFrame(render) // Start the rendering loop

				window.addEventListener("resize", () => {
					resizeCanvas()
				})
			})()
		</script>
	</body>
</html>
